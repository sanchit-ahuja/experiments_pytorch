{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyObLZI+SiHt29eTS+ElCQyh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanchit-ahuja/experiments_pytorch/blob/master/Seq2Seq2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO5x0_Pw28a1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjy6LYIP3EiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 64\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu2687wQShYJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "outputId": "1d078861-c509-4e21-eef4-d4ef88f40589"
      },
      "source": [
        "!python -m spacy download de_core_news_sm\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: de_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz#egg=de_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (47.3.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.6.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.4.5.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (47.3.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arBac3tk3Iu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import de_core_news_sm\n",
        "spacy_de = de_core_news_sm.load()\n",
        "spacy_en = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNn0x-AE3Nf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_de(text):\n",
        "    \"\"\"\n",
        "    Tokenizes German text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zij9ucRR5TOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SRC = Field(tokenize = tokenize_de,use_vocab = True,init_token='<sos>',eos_token='<eos>',lower = True,include_lengths=True)\n",
        "TRG = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg5p-qCM55R5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), \n",
        "                                                    fields = (SRC, TRG))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7hRYI3t57yf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\n",
        "TRG.build_vocab(train_data, min_freq = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N296ttRR5-n9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7aebc0f6-a49d-4277-9428-6eedf414964d"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "     batch_size = BATCH_SIZE,\n",
        "     sort_within_batch = True,\n",
        "     sort_key = lambda x : len(x.src),\n",
        "     device = device)\n",
        "print(train_iterator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torchtext.data.iterator.BucketIterator object at 0x7f46431b5518>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO3ZiyeNBnVB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "03c40708-2541-4080-bf17-65d28e48115c"
      },
      "source": [
        "batch = next(iter(train_iterator)) # BucketIterator return a batch object\n",
        "# batch2 = next(iter())\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIy08wXWUBhV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "ceb27272-5f1f-4503-b75c-3931149b53bb"
      },
      "source": [
        "# dir(batch)\n",
        "batch.trg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
              "        [   4,   14,    4,  ...,  133,    4,   16],\n",
              "        [   9,    6,   64,  ...,  196,    9, 4536],\n",
              "        ...,\n",
              "        [   1,    1,    1,  ...,    1,    5,    1],\n",
              "        [   1,    1,    1,  ...,    1,    3,    1],\n",
              "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWCVdvAb6A5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,input_size,embedding_dim,enc_hid_dim,dec_hid_dim,dropout=0.5):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(input_size,embedding_dim)\n",
        "    self.gru = nn.GRU(embedding_dim,enc_hid_dim,bidirectional = True)\n",
        "    self.fc = nn.Linear(enc_hid_dim*2,dec_hid_dim) #Final encoder hidden vector to be multiplied with decoder hidden vector. That factor of 2 is because of bidirectional output of the gru\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  def forward(self,src,src_len):\n",
        "    # src = [src len, batch_size]\n",
        "    # src_len = [batch_size]\n",
        "    embedded = self.dropout(self.embedding(src))\n",
        "    packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded,src_len) #packing padded sequence. This is done to basically reduce all the padded sequence computation\n",
        "    packed_outputs, hidden = self.gru(packed_embedded) #initial hidden state initialized on own\n",
        "    outputs,_ = nn.utils.rnn.pad_packed_sequence(packed_outputs)\n",
        "    temp_tensor = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1).to(device)\n",
        "    hidden = torch.tanh(self.fc(temp_tensor)).to(device)\n",
        "        #Cat across column\n",
        "    return outputs,hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaz7bXx3aA66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src = batch.src[0].to(device)\n",
        "# print(src)\n",
        "src_len =batch.src[1].to(device)\n",
        "enc= Encoder(len(SRC.vocab),256,512,512).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg5k2m3EcLfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDKhVSWFvzie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self,enc_hid_dim,dec_hid_dim):\n",
        "    super().__init__()\n",
        "    self.attn = nn.Linear((2*enc_hid_dim)+dec_hid_dim,dec_hid_dim) #Again the factor of 2 is for bidirectionality. Additive attention used here\n",
        "    self.v = nn.Linear(dec_hid_dim,1,bias = False) #v.T*Wa*[si;hi] si is encoder hidden states packed and hi decoder hidden state\n",
        "    \n",
        "    #encoder outputs = [src_len,batch_size,enc_hid_dim*2]\n",
        "    #hidden_dec = [batch_size,dec_hid_dim]\n",
        "  def forward(self,hidden,encoder_outputs,mask): #mask is a tensor of shape [batch_size,src_sentence_length] is 1 when src sent token is not a pad and 0 when pad\n",
        "    batch_size = encoder_outputs.shape[1]\n",
        "    src_len = encoder_outputs.shape[0]\n",
        "\n",
        "    #repeat decoder hidden state src_len (T) times. Possible to work with broadcasting as well.\n",
        "    hidden = hidden.unsqueeze(1).repeat(1,src_len,1)\n",
        "    # print(hidden.device)\n",
        "    encoder_outputs = encoder_outputs.permute(1,0,2) #[batch_size,src_len,enc_hid_dim]\n",
        "    #hidden[batch_size,src_len,dec_hidden_dim]\n",
        "    temp_tensor = torch.cat((hidden, encoder_outputs), dim = 2).to(device)\n",
        "    energy = torch.tanh(self.attn(temp_tensor)).to(device) #concatenate wrt dim =2 enc and dec matrix lie on this axis\n",
        "    attention = self.v(energy).squeeze(2) #remove dec_hid_dim\n",
        "    attention = attention.masked_fill(mask == 0,-1e10).to(device) #masking the padded sequence\n",
        "    #attention = [batch_size,src_len]\n",
        "    return F.softmax(attention,dim = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL39aTXScJCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden = torch.randint(10,(1,2),dtype = torch.float).to(device)\n",
        "mask = torch.tensor(([1,1,0,1]),dtype = torch.float).to(device)\n",
        "encoder_output = torch.randint(10,(4,1,4),dtype = torch.float).to(device)\n",
        "attn = Attention(2,2).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJg0hBx5SMWF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66df25fe-3cde-433b-d42c-b27867985933"
      },
      "source": [
        "attn(hidden,encoder_output,mask.to(device)).shape\n",
        "# hidden.device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-XFS0kr4-lB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self,output_dim,emb_dim,enc_hid_dim,dec_hid_dim,dropout,attention):\n",
        "    super().__init__()\n",
        "    self.output_dim = output_dim\n",
        "    self.attention = attention\n",
        "    self.embedding = nn.Embedding(output_dim,emb_dim)\n",
        "    self.gru = nn.GRU((enc_hid_dim*2)+emb_dim,dec_hid_dim) #incoming bidirectionality\n",
        "    # self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "    self.fc_out = nn.Linear((enc_hid_dim*2)+dec_hid_dim+emb_dim,output_dim) #concatenating input_word,weighted source_vector(atH), hidden state\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self,input,hidden,encoder_outputs,mask):\n",
        "    #input = [batch_size]\n",
        "    #hidden = [batch_size,dec_hid_dim]\n",
        "    #enc_outputs = [src_len,batch_size,encoder_hid_dim*2]\n",
        "    input = input.unsqueeze(0) #[1,batch_size]\n",
        "    # print(input.device,'input')\n",
        "    embedded = self.dropout(self.embedding(input).to(device)).to(device) #embedded [1,batch_size,emb_dim]\n",
        "    a = self.attention(hidden,encoder_outputs,mask)\n",
        "    #a = [batch_size,src_len]\n",
        "    a= a.unsqueeze(1)\n",
        "    #a = [batch_size,1,src_len]\n",
        "    encoder_outputs = encoder_outputs.permute(1,0,2)\n",
        "    #encoder_outputs = [batch_size,src_len,enc_hid_dim*2]\n",
        "    weighted = torch.bmm(a,encoder_outputs) #taking the linear combination of all attention vectors here bmm batch multiplication\n",
        "    #weighted = [batch_size,1,enc_hid_dim*2]\n",
        "    weighted = weighted.permute(1,0,2)\n",
        "    rnn_input = torch.cat((embedded,weighted),dim = 2)\n",
        "    #rnn_input = [1,batch_size,emb_dim+enc_hid_dim*2]\n",
        "    #hidden = [1,batch_size,dec_hid_dim]\n",
        "    output,hidden = self.gru(rnn_input,hidden.unsqueeze(0))\n",
        "    #output = [1,batch_size,dec_hid_dim]\n",
        "    #hidden = [1,batch_size,dec_hid_dim]\n",
        "    assert (output == hidden).all() #Effectively they all should be equal\n",
        "    embedded = embedded.squeeze(0)\n",
        "    output = output.squeeze(0)\n",
        "    weighted = weighted.squeeze(0)\n",
        "    # prediction = self.fc_out(torch.cat(output,weighted,embedded),dim = 1)\n",
        "    prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
        "    return prediction,hidden.squeeze(0),a.squeeze(1)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtYsjxP8_BOt",
        "colab_type": "text"
      },
      "source": [
        " $z = h_T = \\tanh(g(h^\\rightarrow_T,h^\\leftarrow_T)) = \\tanh(g(z^\\rightarrow, z^\\leftarrow)) = s_0$,\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHyyw4xaXsIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# decoder = Decoder(1,2,2,2,0.5,attn).cuda()\n",
        "# input = torch.randint(10,(1,),dtype = torch.long).to(device)\n",
        "# print(input.size())\n",
        "# decoder(input,hidden,encoder_output,mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qZMIEtj0fhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self,encoder,decoder,src_pad_idx,device):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.src_pad_idx =src_pad_idx #Pad idx of src_sentence\n",
        "    self.device = device\n",
        "\n",
        "  def create_mask(self,src):\n",
        "    mask = (src != self.src_pad_idx).permute(1,0) #Set non-pads to 1 and pads to 0\n",
        "    return mask\n",
        "  \n",
        "  def forward(self,src,src_len,trg,teacher_forcing_ratio = 0.5):\n",
        "    #src = [src_len,batch_size]\n",
        "    #trg = [trg_len, batch_size]\n",
        "    #src_len = [batch_size]\n",
        "    #target = [target_len,batch_ize]\n",
        "    batch_size = src.shape[1]\n",
        "    trg_len = trg.shape[0]\n",
        "    trg_vocab_size = self.decoder.output_dim\n",
        "    outputs = torch.zeros(trg_len,batch_size,trg_vocab_size).to(self.device)\n",
        "\n",
        "    encoder_outputs,hidden = self.encoder(src,src_len)\n",
        "    input = trg[0,:] #Sos First input to the decoder Shape input 128\n",
        "    mask = self.create_mask(src)\n",
        "    for target in range(1,trg_len):\n",
        "      output,hidden,_=self.decoder(input,hidden,encoder_outputs,mask)\n",
        "      outputs[target] = output\n",
        "      teacher_force = random.random() < teacher_forcing_ratio\n",
        "\n",
        "      top1 = output.argmax(1) #get the highest predicted token from our predictions\n",
        "      input = trg[target] if teacher_force else top1\n",
        "\n",
        "    return outputs\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEVYjtEL7tMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "ENC_HID_DIM = 512\n",
        "DEC_HID_DIM = 512\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MRHxXOcQqt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden = torch.randint(10,(1,2),dtype = torch.float)\n",
        "mask = torch.tensor(([1,1,0,1]),dtype = torch.float)\n",
        "encoder_output = torch.randint(10,(4,1,4),dtype = torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzI4P5wC78ws",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "425b4c9a-68e3-4998-b15c-34910f0f4e6d"
      },
      "source": [
        "def init_weights(m):\n",
        "  for name,param in m.named_parameters():\n",
        "    if 'weight' in name:\n",
        "      nn.init.normal_(param.data,mean = 0,std = 0.01)\n",
        "    else:\n",
        "      nn.init.constant_(param.data,0)\n",
        "model.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(7855, 256)\n",
              "    (gru): GRU(256, 512, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
              "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "    )\n",
              "    (embedding): Embedding(5893, 256)\n",
              "    (gru): GRU(1280, 512)\n",
              "    (fc_out): Linear(in_features=1792, out_features=5893, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRn4hO1S8_8D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00c1914d-6b42-4b7b-be00-efcd7362c295"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 20,518,917 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ancGSQ77IXOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqFglTtwIbNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEF9zPMjIiuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#include_lengths = True, batch.src -> 1st element numericalized tensor,2nd length of each sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZz8xK7tIp7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model,iterator,optimizer,criterion,clip):\n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "  for i,batch in enumerate(iterator):\n",
        "    src,src_len = batch.src\n",
        "    trg = batch.trg\n",
        "    optimizer.zero_grad()\n",
        "    output = model(src,src_len,trg)\n",
        "    #trg = [trg_len,batch_size]\n",
        "    #output = [trg_len,batch_size,output_dim]\n",
        "    output_dim = output.shape[-1]\n",
        "    output = output[1:].view(-1,output_dim) #[trg_len-1*batch_size,output_dim]\n",
        "    trg = trg[1:].view(-1) #SOS first element ignored\n",
        "    #trg = [trg_len-1*batch_size]\n",
        "    loss = criterion(output,trg)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "    optimizer.step()\n",
        "    epoch_loss +=loss.item()\n",
        "  return epoch_loss/len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXv3kJHdPN4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model,iterator,criterion):\n",
        "  model.eval()\n",
        "  epoch_loss = 0\n",
        "  with torch.no_grad():\n",
        "    for i,batch in enumerate(iterator):\n",
        "      src,src_len = batch.src\n",
        "      trg = batch.trg\n",
        "      output = model(src,src_len,trg,0) #turn off teacher forcing\n",
        "      output_dim = output.shape[-1]\n",
        "      output = output[1:].view(-1,output_dim)\n",
        "      trg = trg[1:].view(-1)\n",
        "      loss = criterion(output,trg)\n",
        "      epoch_loss += loss.item()\n",
        "  return epoch_loss/len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Cz_WfllPqO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKvCKvMgPsET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "ee1674af-ec7b-4d02-f874-a507906827c5"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut4-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 1m 34s\n",
            "\tTrain Loss: 5.202 | Train PPL: 181.621\n",
            "\t Val. Loss: 5.041 |  Val. PPL: 154.625\n",
            "Epoch: 02 | Time: 1m 33s\n",
            "\tTrain Loss: 4.426 | Train PPL:  83.580\n",
            "\t Val. Loss: 4.533 |  Val. PPL:  93.064\n",
            "Epoch: 03 | Time: 1m 33s\n",
            "\tTrain Loss: 3.594 | Train PPL:  36.381\n",
            "\t Val. Loss: 3.754 |  Val. PPL:  42.698\n",
            "Epoch: 04 | Time: 1m 33s\n",
            "\tTrain Loss: 2.951 | Train PPL:  19.121\n",
            "\t Val. Loss: 3.423 |  Val. PPL:  30.666\n",
            "Epoch: 05 | Time: 1m 34s\n",
            "\tTrain Loss: 2.552 | Train PPL:  12.836\n",
            "\t Val. Loss: 3.263 |  Val. PPL:  26.127\n",
            "Epoch: 06 | Time: 1m 33s\n",
            "\tTrain Loss: 2.232 | Train PPL:   9.320\n",
            "\t Val. Loss: 3.258 |  Val. PPL:  26.004\n",
            "Epoch: 07 | Time: 1m 34s\n",
            "\tTrain Loss: 2.011 | Train PPL:   7.470\n",
            "\t Val. Loss: 3.137 |  Val. PPL:  23.030\n",
            "Epoch: 08 | Time: 1m 33s\n",
            "\tTrain Loss: 1.791 | Train PPL:   5.997\n",
            "\t Val. Loss: 3.225 |  Val. PPL:  25.152\n",
            "Epoch: 09 | Time: 1m 33s\n",
            "\tTrain Loss: 1.629 | Train PPL:   5.097\n",
            "\t Val. Loss: 3.221 |  Val. PPL:  25.050\n",
            "Epoch: 10 | Time: 1m 33s\n",
            "\tTrain Loss: 1.488 | Train PPL:   4.429\n",
            "\t Val. Loss: 3.275 |  Val. PPL:  26.441\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS8tNWWhPxQM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78b95764-a4d3-485f-f19c-9050d1f7e870"
      },
      "source": [
        "model.load_state_dict(torch.load('tut4-model.pt'))\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 3.144 | Test PPL:  23.193 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfoddhj_twgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "  '''Arg:\n",
        "        sentence: str, input sentence to be translated\n",
        "        src_field: Src_ vocab\n",
        "        trg_field: trg_vocab\n",
        "        model: trained_model\n",
        "        device: cuda\n",
        "        max_len = max_len of sentence\n",
        "      return trg_tokens(translated sentence), attention scores\n",
        "  '''\n",
        "  model.eval()\n",
        "  nlp = de_core_news_sm.load()\n",
        "  tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "  tokens = [src_field.init_token] + tokens+ [src_field.eos_token] #Prepending Sos token and appending eos token to the src sentence\n",
        "  src_indices = [src_field.vocab.stoi[token] for token in tokens]\n",
        "  src_tensor = torch.LongTensor(src_indices).unsqueeze(1).to(device) #converting the indices to tensor and unqueezing a dim for batch_size\n",
        "  src_len = torch.LongTensor([len(src_indices)]).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    encoder_outputs,hidden = model.encoder(src_tensor,src_len)\n",
        "    mask = model.create_mask(src_tensor)\n",
        "    trg_indices = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "    attentions = torch.zeros(max_len,1, len(src_indices)).to(device) #storing attention vectors for all the src_words\n",
        "    for i in range(max_len):\n",
        "      trg_tensor = torch.LongTensor([trg_indices[-1]]).to(device) #flatten the trg_indices list\n",
        "      with torch.no_grad():\n",
        "        output,hidden,attention = model.decoder(trg_tensor,hidden,encoder_outputs,mask)\n",
        "        attentions[i] = attention\n",
        "        pred_token = output.argmax(1).item() #Getting the token for the word that had max softmax score\n",
        "        trg_indices.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "          break #Reached the end of sentence\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indices]\n",
        "\n",
        "    return trg_tokens[1:], attentions[:len(trg_tokens)-1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktyWeVACw-hE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4f30da9c-3f5c-46a7-ba1a-ca33e2a326a1"
      },
      "source": [
        "example_idx = 20\n",
        "src = vars(train_data.examples[example_idx])['src']\n",
        "trg = vars(train_data.examples[example_idx])['trg']\n",
        "# print(dir(src))\n",
        "src = ' '.join(src)\n",
        "# src = 'mein name ist sam'\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ein großes bauwerk ist kaputt gegangen und liegt auf einer fahrbahn .\n",
            "trg = ['a', 'large', 'structure', 'has', 'broken', 'and', 'is', 'laying', 'in', 'a', 'roadway', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDI3Dg6fxEye",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "53ab346e-b264-4851-dd78-1567f945ed3f"
      },
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "print(translation)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['a', 'large', 'structure', 'is', '<unk>', 'and', 'laying', 'on', 'a', 'roadway', '.', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhJ__267xGME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRG.vocab.stoi['name']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKMzYqery5wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display_attention(sentence,translation,attention):\n",
        "  fig = plt.figure(figsize = (10,10)) #Defining the fig size \n",
        "  ax = fig.add_subplot(111)\n",
        "  attention = attention.squeeze(1).cpu().detach().numpy()\n",
        "  cax = ax.matshow(attention, cmap = 'bone')\n",
        "  ax.tick_params(labelsize = 15) #Setting the indices of the matrix\n",
        "  ax.set_xticklabels(['']+['sos']+ [t.lower() for t in sentence] +['eos'],rotation = 45)\n",
        "  ax.set_yticklabels([''] + translation)\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()\n",
        "  plt.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1X0jskP0c0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "outputId": "db30e1fb-3a6d-4b75-dd34-5ca6fe961788"
      },
      "source": [
        "display_attention(src, translation, attention)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJOV3d940fGm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "79e957d8-5eb1-4ee0-9f24-0ae8035ee9da"
      },
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "    \n",
        "    for datum in data:\n",
        "        \n",
        "        src = vars(datum)['src']\n",
        "        trg = vars(datum)['trg']\n",
        "        \n",
        "        pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len)\n",
        "        \n",
        "        #cut off <eos> token\n",
        "        pred_trg = pred_trg[:-1]\n",
        "        \n",
        "        pred_trgs.append(pred_trg)\n",
        "        trgs.append([trg])\n",
        "        \n",
        "    return bleu_score(pred_trgs, trgs)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-7d9d8b176fbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbleu_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_field\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_field\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/metrics.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mngrams_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'ngrams_iterator'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeWEu7z5055C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchtext.data as data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf5kdAJ20-0h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "8491eb85-476b-4467-a0a3-7ec9ac50136d"
      },
      "source": [
        "dir(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BPTTIterator',\n",
              " 'Batch',\n",
              " 'BucketIterator',\n",
              " 'Dataset',\n",
              " 'Example',\n",
              " 'Field',\n",
              " 'Iterator',\n",
              " 'LabelField',\n",
              " 'NestedField',\n",
              " 'Pipeline',\n",
              " 'RawField',\n",
              " 'ReversibleField',\n",
              " 'SubwordField',\n",
              " 'TabularDataset',\n",
              " '__all__',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " 'batch',\n",
              " 'dataset',\n",
              " 'example',\n",
              " 'field',\n",
              " 'get_tokenizer',\n",
              " 'interleave_keys',\n",
              " 'iterator',\n",
              " 'pipeline',\n",
              " 'pool',\n",
              " 'utils']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1wS1u221IA3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "66c6d5a4-406d-4798-a21d-3a8a7d49cb7b"
      },
      "source": [
        "pip install -U torchtext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n",
            "\r\u001b[K     |█████                           | 10kB 15.5MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.41.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.5.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2020.4.5.2)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext) (0.16.0)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.91 torchtext-0.6.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torchtext"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dsl51ADN1K62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}